{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ___Background Subtraction Method___\n",
    "Background subtraction is a technique used to separate the foreground from the background in a video stream.\n",
    "\n",
    "The basic idea is to subtract the background image from the current frame of the video stream to obtain the foreground objects.\n",
    "The background image can either be a static image or a dynamically updated image that adapts to changes in the scene.Resulting foreground objects can then be used for further processing, such as object detection or tracking.\n",
    "\n",
    "---\n",
    "### ___Types of Background Subtraction___\n",
    "The most commonly used algorithms are:\n",
    "* Gaussian Mixture-based Background/Foreground Segmentation Algorithm (MOG2)\n",
    "* Adaptive Background Mixture Model (ABM):\n",
    "* Codebook-based Background Subtraction (CBBS)\n",
    "* Approximate Median Filter-based Background Subtraction (AMF)\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the objects need for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Camera obejct or set the path of the vedio to process\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Created the Background Subtractor\n",
    "mog = cv2.createBackgroundSubtractorMOG2()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process the Vedio Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Read a frame from the video stream\n",
    "    ret, frame = cap.read()\n",
    "    # Convert Image to GrayScale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply background subtraction to the current frame\n",
    "    fgmask = mog.apply(gray)\n",
    "    \n",
    "    # Apply morphological operations to reduce noise and fill gaps\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    fgmask = cv2.erode(fgmask, kernel, iterations=1)\n",
    "    fgmask = cv2.dilate(fgmask, kernel, iterations=2)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Ignore small contours\n",
    "        if cv2.contourArea(contour) < 1000:\n",
    "            continue\n",
    "        \n",
    "        # Draw bounding box around contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the Image    \n",
    "    cv2.imshow('Motion Detection', frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
