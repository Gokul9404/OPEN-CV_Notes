{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame Difference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frame Differencing and Summing Technique (DST for short) is a very simple yet effective computer vision technique. We know that a video consists of multiple consecutive frames. And these frames are made up of pixels which consist of colors.\n",
    "\n",
    "* So, suppose that we take any two consecutive frames from a video. \n",
    "* Now, letâ€™s subtract the current frame from the previous frame. \n",
    "    > If they contain the same information (RGB color values), then the resulting frame will be completely black. \n",
    "    \n",
    "    > If the current frame consists of some newer information or pixel values, then we will see some sort of white patches after the subtraction.\n",
    "    > This tells us that something in the video has moved or changed position. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare the motion detection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionDetection(Capture_Src):\n",
    "    if Capture_Src == 0:\n",
    "        cap = cv.VideoCapture(0)\n",
    "    else:\n",
    "        cap = cv.VideoCapture(\"./vtest.avi\")\n",
    "        length = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "        # print( length )\n",
    "\n",
    "    # Read two consequtive frames from the source and convert them into gray images\n",
    "    _, frame1 = cap.read()\n",
    "    frame1_gray = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "    _, frame2 = cap.read()\n",
    "    frame2_gray = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # If the vedio reached it's end terminate the method working\n",
    "        if Capture_Src != 0:\n",
    "            cur_frame_no = int(cap.get(cv.CAP_PROP_POS_FRAMES))\n",
    "            if length == cur_frame_no:\n",
    "                print(\"Video length finished\")\n",
    "                break\n",
    "\n",
    "        # Get the absolute difference btw conseqtive frames \n",
    "        diff = cv.absdiff(frame1_gray, frame2_gray)\n",
    "\n",
    "        # Apply blurring to the abs_diff frame\n",
    "        blur = cv.GaussianBlur(diff, (5, 5), 0)\n",
    "\n",
    "        # Thresholding the frame\n",
    "        _, thresh = cv.threshold(blur, 20, 255, cv.THRESH_BINARY)\n",
    "        \n",
    "        # Generate the kernal of 3x3 size\n",
    "        Krnl = cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
    "        # Applying the dilation to the threshold_img\n",
    "        dilated = cv.dilate(thresh, Krnl, iterations=3)\n",
    "        \n",
    "        # Detect the countour and draw it on the Colored frame\n",
    "        contours, _ = cv.findContours(dilated, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            (x, y, w, h) = cv.boundingRect(contour)\n",
    "            # if the contour area is less than 700, skip the contour\n",
    "            if cv.contourArea(contour) < 700:\n",
    "                continue\n",
    "            cv.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv.putText(frame1, \"Status: {}\".format('Movement'), (10, 20), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "\n",
    "        # cv.imshow(\"Video_thresh\", thresh)\n",
    "        cv.imshow(\"Video\", frame1)\n",
    "\n",
    "        # set frame to the next (both colored and gray_scaled)\n",
    "        frame1 = frame2\n",
    "        frame1_gray = frame2_gray\n",
    "        # read the next frame and set it's gray-scaled copy\n",
    "        ret, frame2 = cap.read()\n",
    "        frame2_gray = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "        # if user interupts and press 'q' stop/terminate the process\n",
    "        if cv.waitKey(10) == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video length finished\n"
     ]
    }
   ],
   "source": [
    "# Run the motioDetection function\n",
    "if __name__ == \"__main__\":\n",
    "    motionDetection(1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
